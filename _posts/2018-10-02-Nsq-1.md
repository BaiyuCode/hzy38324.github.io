---
layout:     post                    # 使用的布局（不需要改）
title:    如何设计出一个靠谱的消息中间件             # 标题 
subtitle:   #副标题
date:       2018-10-02              # 时间
author:     ZY                      # 作者
header-img: img/banner/The-Hobbit-Movie-HD-Wallpaper.jpg    #这篇文章标题背景图片
catalog: true                       # 是否归档
tags:                               #标签
    - Nsq
    - 消息中间件
    - 分布式
---
# 前言

好久不见。  

从这篇文章开始，我将带大家走进消息中间件的奇妙世界。  

为什么说消息中间件很奇妙呢？因为它本质上就是一种很简单的数据结构——队列，但是一条队列肯定是当不成中间件的，你必须要考虑性能、容灾、可靠性等等因素。这也给我的写作提供了一些思路，我将从队列开始，给你演示一条队列是如何进化成一个靠谱的中间件的。  

消息中间件的实现有很多，有新贵Kafka、RocketMq，也有老牌劲旅RabbitMq和ActiveMq，不过我最后选择了Nsq来讲解，因为它极简、清爽，用起来舒服，讲起来也好理解，更重要的是，通过对Nsq的学习，我们很容易扩展到消息中间件的通用层面，对学习其他Mq，乃至优化和设计自己的Mq都有很大帮助。  

这一系列的文章，将有以下这些topics:  

1. 为什么要使用消息中间件
2. 如何从一条队列，进化成一个靠谱的消息中间件：这一节，将带你从演化的视角，认识Nsq的各个组件
3. Bringing It All Together：从微观层面了解完Nsq后，我们再从宏观的视角，把上一节学的东西串起来，看一条消息，是如何从生产到被消费的
4. 一些实现细节：从近到远的看完了Nsq，现在让我们再一次把镜头拉近，看看Nsq在处理一些细节问题上的智慧，这对我们理解消息中间件，将有很大帮助
5. 如何设计一个消息中间件：由近到远，由远及近，我们已经把Nsq看了个遍，是时候尝试总结一下，如何设计一个消息中间件了
6. Nsq的不足：作为一个极简的Mq，Nsq肯定做不到的面面俱到，那么Nsq有哪些不足呢？  
7. Nsq vs Kafka：Nsq的那些不足，Kafka几乎都给解决了，毕竟人家是重量级Mq，功能自然强大的多。虽然大多数业务，使用Nsq已经可以解决问题，但还是了解一下，Kafka是怎么解决那些Nsq不屑于解决的问题吧~
8. 有赞自研版Nsq：基于Nsq的一些不足，和对Kafka实现思路的借鉴，有赞对Nsq进行了自研开发，这一节，让我们了解一下有赞的改进思路
9. ...  

# 为什么要使用消息中间件

假设我们在淘宝下了一笔订单后，淘宝后台需要做这些事情：

1. 消息通知系统：通知商家，你有一笔新的订单，请及时发货
2. 推荐系统：更新用户画像，重新给用户推荐他可能感兴趣的商品
3. 会员系统：更新用户的积分和等级信息  
4. ...  

于是一个创建订单的函数，至少需要取调用三个其他服务的接口，就像这样：
![](/img/post/2018-10-02-Nsq-1/without-mq.png)  

写成伪码：  
```
createOrder(...) {
    doCreateOrder(...);
    
    // 调用其他服务接口
    sendMsg(...);
    updateUserInterestedGoods(...);
    updateMemberCreditInfo(...);
}
```

这样的做法，显然很挫，至少有两个问题：

1. 过度耦合：如果后面创建订单时，需要触发新的动作，那就得去改代码，在原有的创建订单函数末尾，再追加一行代码
2. 缺少缓冲：如果创建订单时，会员系统恰好处于非常忙碌或者宕机的状态，那这时更新会员信息就会失败，我们需要一个地方，来暂时存放无法被消费的消息

我们需要一个消息中间件，来实现解耦和缓冲的功能。  
![](/img/post/2018-10-02-Nsq-1/with-mq.png)  

消息中间件的实现很多，比较常见的有kafka、rocketmq以及我们今天要讲的nsq。  

相比于前面两个mq，nsq可以说是非常轻量级的，理解了它，也有助于学习kafka和rocketmq。所以本文以Nsq为例，来讲解消息中间件的一些实现细节。  

首先，让我们从消息中间件的最原始形态开始，一种常见的数据结构 —— 队列。  

# Nsq 1.0 —— 我是一条队列

我们在订单系统和其他系统的中间，引入了一个消息中间件，或者说，引入了一条队列。  

当订单系统创建完订单时，它只需要往队列里，塞入（push）一条topic为“order_created”的消息。  
接着，我们的nsq1.0，会把这条消息，再推送给所有订阅了这个topic的消息的机器，告诉他们，“有新的订单，你们该干嘛干嘛”。  

这样一个简单的队列，就解决了上面的两个问题：  

- 解耦：如果后面有新的动作，需要在创建订单后执行，那么只需要让新同学自己去订阅topic为“order_created”的消息即可
- 缓冲：如果会员系统现在很忙，没空处理消息，那么只需跟nsq说，“我很忙，不要再发消息过来了”，那么nsq就不会给它推送消息，或者会员系统出了故障，消息虽然推送过去了，但是它给处理失败了，那么也只需给nsq回复一个“requeue”的命令，nsq就会把消息重新放入队列，进行重试。  

# Nsq 2.0 —— channel

作为一个靠谱的中间件，你必须做到：高效、可靠、方便。  

上面这个使用一条简单的队列来实现的消息中间件，肯定是不满足这三点的。  

首先，假设我的会员系统，部署了三台实例，他们都订阅了topic为“order_created”的消息，那么一旦有订单创建，这三台实例就都会收到消息，并且去更新会员积分信息，而其实我只需要更新一次就ok了。  

这就涉及到一个消费者组（Comsumer Group）的概念。消费者组是Kafka里提到的，在Nsq，对应的术语是channel。  

会员系统的三个实例，当它们收到消息时，要做的事情是一样的，并且只需要有有一个实例执行，那么它们就是一个消费者组里面的，要标识为同一个channel，比如说叫“update_memeber_credit”的channel，而短信系统和推荐系统，也要有自己的channel，用来和会员系统作区分，比如说叫“send_msg”和“update_user_interesting_goods”  

当nsq收到消息时，会给每个channel复制一份消息，然后channel再给对应的消费者组，推送一条消息。消费者组里有多个实例，那么要推给谁呢？这就涉及到负载均衡，比如有一个消费者组里有ABC三个实例，这次推给了A，那么下次有可能是推送给B，再下次，也许就是C ...    

nsq官网上的一张动图，非常好的解释了这个过程：
![](/img/post/2018-10-02-Nsq-1/nsq-topic-channel-consumer.gif)  

稍微解释一下，图中，nsq上有一个叫”clicks“的topic，”clicks“下面有三条channel，也就是三个消费者组，其中channel名称为”metrics“的，有三个实例。消息A来到nsq后，被复制到三条channel，接着，在metrics上的那个A，被推送到了第二个实例上。接着，又来了一个叫B的消息，这一次，B被推送给了第一个实例进行处理。  


# Nsq 3.0 —— nsqlookup

上面讲过，nsq收到生产者生产的消息后，需要将消息复制多份，然后推送给对应topic和channel的消费者。  

那么，nsq怎么知道哪些消费者订阅了topic为“order_created”的消息呢？  

总不能在配置文件里写死吧？ip为10.12.65.123的，端口8878，这个消费者的topic是xxx，channel是xxx，...   

因此，我们需要一个类似于微服务里头的注册中心的模块，来实现服务发现的功能，这就是nsqlookup.  

nsqlookup提供了类似于etcd、zookeeper一样的kv存储服务，里面记录了topic下面都有哪些nsq。  
nsqlookup提供了一个`/lookup`接口，比如你想知道哪些nsq上面，有topic为test的消息，那么只需要调一下：
```
curl 'http://127.0.0.1:4161/lookup?topic=test'
```

nsqlookup就会给你返回对应topic的nsq列表：
```
{
  "channels": [
    "xxx"
  ],
  "producers": [
    {
      "remote_address": "127.0.0.1:52796",
      "hostname": "hongzeyangdeMacBook-Pro",
      "broadcast_address": "127.0.0.1",
      "tcp_port": 4150,
      "http_port": 4151,
      "version": "1.0.0-compat"
    }
  ]
}
```
接着消费者只需要遍历返回的json串里的producers列表，把broadcast_address和tcp_port或者http_port拼起来，就可以拿到要建立连接的url地址。 

消费者会和这些nsq，逐个建立连接。nsq收到对应topic的消息后，就会给和他们建立连接的消费者，推送消息。  

这个过程，可以从nsq的消费者客户端实现的代码中，很清楚的看出来。  

我这里用nsq的Java 客户端实现[brainlag/JavaNSQClient](https://github.com/brainlag/JavaNSQClient)作为例子。  

首先，调用lookup接口，获取拥有对应topic的nsq列表。注意看代码，里面是遍历了nsqlookup的列表，然后把所有lookup的返回结构，进行合并。    
com.github.brainlag.nsq.lookup.DefaultNSQLookup#lookup：  
![](/img/post/2018-10-02-Nsq-1/nsq-client-lookup.png)  

画红框的地方，正是之前讲的拼凑逻辑。  

接着和旧的nsq列表比较，进行删除和新增，保证本地的nsq列表数据是最新的。  
com.github.brainlag.nsq.NSQConsumer#connect:  
![](/img/post/2018-10-02-Nsq-1/nsq-client-remove-add.png)  

当然，这个过程不会只在消费者启动时才执行，而是定期去执行，不断去获取最新的nsq列表。  
![](/img/post/2018-10-02-Nsq-1/nsq-client-schedule.png)  

# Nsq 4.0 —— nsqd集群

作为一个靠谱的中间件，你必须支持集群部署，这样才能实现可靠、高效。  

nsq的集群部署非常简单，官方推荐一个生产者对应的部署一个nsqd：  
> What is the recommended topology for nsqd?
> 
> We strongly recommend running an nsqd alongside any service(s) that produce messages.  

![](/img/post/2018-10-02-Nsq-1/nsq-cluster.png)  

这也能解释，为什么上面的`/lookup`接口，返回的属性是叫`producers`，而不是叫`nsqs`，因为nsq认为一个producer，就对应一个nsq。  

当然这样的做法有不少坏处，如果生产者对应的nsq挂掉了，那它就生产不了消息了。而且每个生产者都要部署一个nsq，未免有些奢侈。  

不过对于大多数业务来说，这样的nsq已经够用。如果你像有赞一样，拥有一群Go语言大神，那也不妨对nsq做一下改造。一个简单的思路，就是模仿消费者侧的代码，通过nsqlookup来动态获取有效的nsq地址，然后往其中一个nsq发布消息。    

# 小结（1）

这篇文章主要从一个演化的视角，介绍了一条队列，如何逐步进化成一个消息中间件，也介绍了Nsq的几大模块：  

- nsq: 存储消息的地方，每个topic可以有一个或者多个的channel
- nsqlookup：实现服务发现的模块
- nsqadmin：文章中没有提及，主要是进行可视化管理的web ui工具

下一讲，我将把这一次学到的东西串起来，了解一下，一条消息，是如何从生产到被消费的。  

# Bringing It All Together

上面讲的都是些细碎的知识点，现在，让我们把这些知识点整合起来，来看看，一条消息，是如何从生产到被消费的。  

首先，我们要启动各个服务，生产者、消费者、nsq、nsqlookup.  

假设消费者最先启动，它要消费topic为”order_created“的消息，这时候它向nsqlookup调用`/lookup`接口，试图获取对应topic的nsq。由于nsqlookup还没启动，因此获取失败，不过这并不影响消费者的启动流程，因为它会每隔一段时间，去尝试重新拉取最新的数据。  
![](/img/post/2018-10-02-Nsq-1/nsq-java-client-connect-failed.png)  

消费者可以使用nsq java客户端的示例代码来模拟：  
```java
public static void main(String[] args) {
        NSQLookup lookup = new DefaultNSQLookup();
        lookup.addLookupAddress("localhost", 4161);
        NSQConsumer consumer = new NSQConsumer(lookup, "order_created", "send_msg", (message) -> {
            System.out.println("received: " + message);
            //now mark the message as finished.
            message.finished();

            //or you could requeue it, which indicates a failure and puts it back on the queue.
            //message.requeue();
        });

        consumer.start();
    }
```
为了方便调试，我将向nsqlookup查询最新nsq信息的时间间隔，由一分钟一次，改为了十秒一次：  
com.github.brainlag.nsq.NSQConsumer#lookupPeriod:  
```java
private long lookupPeriod = 10 * 1000; // how often to recheck for new nodes (and clean up non responsive nodes)
```

接着，我们启动了nsq和nsqlookup，这下消费者可以调通nsqlookup的接口了，不过由于nsq上面还没有任何topic，因此`/lookup`接口返回的`producers`数组是空，因此消费者仍然无法向任何nsq订阅消息。  

然后，我们调用这条命令，在nsq上创建新的topic:  
```
curl -X POST http://127.0.0.1:4151/topic/create?topic=order_created
```
nsq创建完topic后，会自动向nsqlookup注册新的topic节点。 如下图，是我执行了创建topic命令后，nsq和nsqlookup控制台打印的日志：  

![](/img/post/2018-10-02-Nsq-1/nsq-create-topic.jpg)  

当消费者下次过来nsqlookup调用`/lookup`接口时，接口就会告诉它，已经有一台nsq，上面有”order_created“的topic了。于是消费者拿到那台nsq的ip和端口，和它建立连接，向它发送`sub`命令，带上topic和channel参数，订阅这台nsq上面的”order_created“的消息。

![](/img/post/2018-10-02-Nsq-1/nsq-client-subscribe-code.png)  

![](/img/post/2018-10-02-Nsq-1/nsq-client-subscribe.png)  

上图中，可以看到，第一次查询到的信息里，channel数组是空，建立完连接，订阅后，第二次再去查，就可以看到有新的channel。  

这是因为，当消费者的channel不存在时，nsq将会创建一条新的channel。和之前创建topic类似，创建完channel，nsq会向nsqlookup注册新的channel节点。不一样的是，channel会在订阅时，自动创建，而topic，需要我们事先在nsq创建好。  

然后，我们启动了生产者，生产者向nsq发布了topic为”order_created“的消息，在这里我们使用下面这条命令来模拟发布消息：  
```
curl -d 'hello world' 'http://127.0.0.1:4151/pub?topic=order_created'
```
消息发布给nsq后，就像之前讲的，nsq会把消息复制到topic下的所有channel中，每个channel复制一份，接着channel再向和它建立连接的其中一个消费者实例，推送这条消息。  

此时，在消费者侧，已经接收到了消息，控制台打印接收到的消息内容：  
![](/img/post/2018-10-02-Nsq-1/nsq-consumer-consume.png)  

你可以启动多个消费者，比如再启动一个不同channel的消费者，你会发现，两个消费者都会收到消息；而假如你启动的消费者，channel还是”send_msg“，那么两个消费者只有一台会收到消息，而且nsq默认的负载均衡策略是轮询，也就是这一次消费者1收到消息，下一次，就是消费者2收到消息。  

感兴趣的读者不妨在本地跑下nsq玩玩，尝试尝试。  

# 一些细节

这一章，咱们来聊聊几个有趣的细节。  

1、消息至少被投递一次  
这是nsq的[Guarantees](https://nsq.io/overview/features_and_guarantees.html#guarantees)中的一个：

> messages are delivered at least once

消息投递策略，是消息中间件的特有属性，不同的消息中间件，对投递策略的支持也不同。比如Kafka，就支持最多一次、至少一次、准确一次三种策略，而nsq，则只支持最常见的一种，也就是至少一次。  

怎样保证消息至少被投递一次呢？  

如果消费者收到消息，并成功执行，那么就给nsq返回`FIN`，代表消息已被成功执行，这时nsq就可以把内存中，也就是channel里的消息干掉；  

而如果消费者处理消息时发生了异常，需要重试，那么就给nsq返回`REQ`，代表requeue，重新进入队列的意思，nsq就会把消息重新放到队列中，再次推送给消费者(这一次可能是另一个消费者实例)。如果消费者迟迟没有给nsq回响应，超过了最大等待时间，那么nsq也会将消息requeue.  

所以，消费者必须保证操作的幂等性。  

2、重试次数  
nsq推送过来的消息里，有个`attempts`字段，代表着尝试的次数，一开始是1，每次客户端给nsq会`REQ`响应后，nsq再次推送过来的消息，`attempts`都会加1，消费者可以按照自己的需要，对重试次数进行限制，比如希望最多尝试6次，那么就在消费者的处理逻辑中，判断`attempts <= 6`，是，则执行处理逻辑，否则，打印日志或者做其他处理，然后直接返回`FIN`，告诉nsq不要再重试。  

3、消息无序性  
消息是否有序，是消息中间件的特有属性。通过上面的分析，很明显，nsq的消息是无序的，这也在nsq官网里的[Guarantees](https://nsq.io/overview/features_and_guarantees.html#guarantees)中有提到：  

> messages received are un-ordered

比如说channel A里现在有两条消息，M1和M2，M1先产生，M2后产生，channel A分别将M1和M2推送给了消费者 C1和C2，那么有可能C1比C2先处理完消息，这样是有序的；但也有可能，C2先处理了，这样M2就比M1先被处理，这样就是无序的。  

正是由于这种一有消息就推送的策略，nsq里的消息处理是无序的。  

4、push or pull  
push还是pull，这也是在设计一个消息中间件时，必须要考虑的问题。Kafka用的是pull，而Nsq采取的是push。  

相比于pull，push的好处不言而喻 —— 消息处理更加实时，一旦有消息过来，立即推送出去，而pull则具有不确定性，你不知道消费者什么时候有空过来pull，因此做不到实时消息处理。这也是有赞只把Kafka用在那些对实时性要求不高的业务上的原因，比如大数据统计。  

也正是因为采用了push，nsq选择把消息放到内存中，只有当内存占用超过`--mem-queue-size`配置的限制时，才会对消息进行持久化，把消息保存到磁盘中，简称”刷盘“。  

而采用pull的Kafka，则直接把消息存储到磁盘。  

push + 内存存储，or pull + 磁盘存储，这也是消息中间件设计时的一些套路。  

当然，push机制也有缺陷，那就是当消费者很忙碌的时候，你还一直给它push，那只会逼良为娼，所以采用push的消息中间件，必须要进行流控。  

> 关于push和pull的分析，后面再和大家深入探讨，有兴趣的同学可以先看下Kafka官网的这篇分析：[Push vs Pull](https://kafka.apache.org/documentation/#design_pull)

5、流控  
Nsq流控的方式非常简单，当消费者和nsq建立好连接，准备好接受消息时，会给nsq回一个`RDY`的响应，同时带上一个`rdy_count`，代表准备接受消息的数量，于是nsq会给消费者推送消息，每推送一条，对应连接的`rdy_count`就减1(如果是批量推送，则批量减)，直到连接的`rdy_count`变成0，则不再继续推送消息。  

当消费者觉得自己可以接收很多消息时，只需再发一次`RDY`命令，就可以更新连接的`rdy_count`，nsq就会继续给消费者推送消息。  

在java客户端实现中，采取的策略是，如果发现已经处理完超过一半的消息，就再去发`RDY`消息，要求nsq送更多消息过来。  
com.github.brainlag.nsq.NSQConsumer#processMessage：  
![](/img/post/2018-10-02-Nsq-1/nsq-client-request-more.png)  


# 如何设计一个消息中间件

我们从微观到宏观，再从宏观到微观的了解了一遍Nsq，现在让我们试着总结一下，如何设计一个消息中间件。  

首先，你是一个中间件，必须有中间件的样子，一条队列，肯定不能作为中间件，因为你不满足：  
- no SPOF: SPOF = Single Point of Failure，你就一个单点，就一台服务器，挂了整个系统的消息都跑不通了，你必须要有替补、要有搭档。这一点，解决思路就是采用集群，nsq和nsqlookup，都支持集群架构  
- 可拓展性强：当一台服务器不够用时，你是否支持方便的横向扩展？nsq的扩展非常简单，默认一个生产者配置一个nsq，如果你需要俩，那就配置两个nsq地址即可
- 可靠性强：这一点，nsq并不具备，默认情况下，消息是保存到内存的，一旦系统崩溃了，消息就没了。就算消息持久化到磁盘了，也只是做了一次备份，不像Kafka的partition机制，可以做多次备份
- 性能好：这点毋庸置疑，采用push+内存的实现策略，再加上上面提到的高可拓展性，nsq的性能可以得到保障  
- ...

其次，你是一个消息中间件，消息中间件的一些特殊属性，你要支持或者作出取舍：  

- 消息投递策略：消息投递是至少一次，还是最多一次，还是需要控制在准确一次？nsq选择的是至少一次，这种适用面最广的方式，Kafka则支持全部三种，当然，这也给系统引入了更多的复杂性，而nsq则选择一如既往的”极简“  
- 消息时序性：为了性能考虑，nsq选择了不去无序，让消息飞~ 当然，如果你能设计出一套可以在topic级别进行时序性控制的消息中间件，是最牛逼不过了，比如有赞自研的nsq  
- push or pull：为了追求实时性，nsq选择了push，不同的消息中间件有不同的实现策略
- 内存 or 磁盘：通常，如果你选择了push，那么对应的就会选择内存，当然为了消息可靠性，你还是得做一些刷盘的操作  
- ...   

# Nsq的不足

生产者不能通过服务发现，动态发现nsq
消息无序 无法实现顺序消费
数据可靠性： 消息放在了内存，就算刷盘 也只是备份了一次  缺少多次备份
消息历史回溯
消息重放

kafka
下集预告  Nsq vs Kafka
Kafka简明教程 链接

有赞自研

# Nsq vs Kafka

# 有赞自研Nsq

# 总结

nsq的几大模块


# 参考

- [Nsq官方文档](https://nsq.io/)


